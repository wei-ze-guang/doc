## 消费消息的的时候重复消费或者消息丢失  
## poll()方法
- 设置为0的话，不管拉没拉到数据都直接返回，用来处理延迟
- 设置为Integer.MAX_VALUE,就是一直消费信息  
### 消息丢失，消息丢失情况
1. 消费者拉取数据后还没处理完，Kafka 就自动提交了 offset。结果消费者宕机，重启后从“已提交的 offset”继续消费，跳过了没处理完的消息。  
** 讲人话就是开启了自动提交，但是确实提交了，但是我消息还没处理就提交了，一旦提交成功，但是消费时候出问题了。下次拉取就会从最新的拉取，就会消息丢失 ，提交发生再处理信息之前
```text
poll -> offset=100 ~ 105
还没处理完 -> auto.commit.interval.ms 到期 -> offset=106 被提交
宕机 -> 重启从 106 开始消费，100 ~ 105 丢失

``` 
- 解决方法：
  - 关闭自动提交：enable.auto.commit=false
  - 使用 commitSync() / commitAsync() 在消息处理完之后手动提交 offset  

### 重复消费  
1. 